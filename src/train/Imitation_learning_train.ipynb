{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8p8LgdP85MJ",
        "outputId": "7a5f8955-c91f-4885-9240-03c1a322b5a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-chess\n",
            "  Downloading python_chess-1.999-py3-none-any.whl.metadata (776 bytes)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Collecting chess<2,>=1 (from python-chess)\n",
            "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n",
            "Building wheels for collected packages: chess\n",
            "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=9e8011aedc9cbd8a930cfa692f6e9480267280a673a4739fd3076e4ba3195c42\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/1f/4e/8f4300f7dd554eb8de70ddfed96e94d3d030ace10c5b53d447\n",
            "Successfully built chess\n",
            "Installing collected packages: chess, python-chess\n",
            "Successfully installed chess-1.11.2 python-chess-1.999\n",
            "‚úÖ Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# [CELL 1] Setup Environment\n",
        "!pip install python-chess tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import chess\n",
        "import chess.pgn\n",
        "import os\n",
        "import pickle\n",
        "import shutil\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ki·ªÉm tra GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"‚úÖ Device: {device}\")\n",
        "if device.type == 'cpu':\n",
        "    print(\"‚ö†Ô∏è Warning: B·∫°n ƒëang ch·∫°y tr√™n CPU. H√£y b·∫≠t GPU T4 trong Runtime > Change runtime type.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwSvJNMJ-OjF",
        "outputId": "929734ef-99a6-4b6c-b0cf-d8ce790c399e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [CELL 2] Mount Drive & Setup Directories\n",
        "\n",
        "\n",
        "# ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n l√†m vi·ªác tr√™n Drive\n",
        "# B·∫°n c√≥ th·ªÉ ƒë·ªïi t√™n th∆∞ m·ª•c 'ChessAI' t√πy √Ω\n",
        "BASE_PATH = '/content/drive/MyDrive/TriÃÅ tueÃ£ÃÇ nhaÃÇn taÃ£o/BTL_2'\n",
        "DATA_PATH = os.path.join(BASE_PATH, 'data_chess')\n",
        "DATA_PATH = os.path.join(DATA_PATH, 'data_2000')\n",
        "MODEL_PATH = os.path.join(BASE_PATH, 'weights')\n",
        "\n",
        "# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥\n",
        "#os.makedirs(os.path.join(DATA_PATH, 'raw_pgn'), exist_ok=True)\n",
        "os.makedirs(os.path.join(DATA_PATH, 'processed'), exist_ok=True)\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"üìÇ Working directory created at: {BASE_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzO84wYq9UKW",
        "outputId": "04948e62-e19c-47df-823c-0091e1d2b142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Working directory created at: /content/drive/MyDrive/TriÃÅ tueÃ£ÃÇ nhaÃÇn taÃ£o/BTL_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [CELL 3] Architecture: SmallResNet\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, num_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1, stride=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
        "        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1, stride=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class SmallResNet(nn.Module):\n",
        "    def __init__(self, num_res_blocks=6, num_channels=64, action_size=4672):\n",
        "        super(SmallResNet, self).__init__()\n",
        "        # Input: 32 channels (Current + History + Aux) [cite: 30]\n",
        "        self.conv_input = nn.Conv2d(32, num_channels, kernel_size=3, padding=1, stride=1, bias=False)\n",
        "        self.bn_input = nn.BatchNorm2d(num_channels)\n",
        "\n",
        "        # Backbone: Residual Tower\n",
        "        self.res_blocks = nn.ModuleList([\n",
        "            ResidualBlock(num_channels) for _ in range(num_res_blocks)\n",
        "        ])\n",
        "\n",
        "        # Policy Head (Actor) [cite: 43]\n",
        "        self.policy_conv = nn.Conv2d(num_channels, 32, kernel_size=1, stride=1, bias=False)\n",
        "        self.policy_bn = nn.BatchNorm2d(32)\n",
        "        self.policy_fc = nn.Linear(32 * 8 * 8, action_size)\n",
        "\n",
        "        # Value Head (Critic) [cite: 44]\n",
        "        self.value_conv = nn.Conv2d(num_channels, 3, kernel_size=1, stride=1, bias=False)\n",
        "        self.value_bn = nn.BatchNorm2d(3)\n",
        "        self.value_fc1 = nn.Linear(3 * 8 * 8, 64)\n",
        "        self.value_fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn_input(self.conv_input(x)))\n",
        "        for block in self.res_blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Policy: Softmax\n",
        "        p = F.relu(self.policy_bn(self.policy_conv(x)))\n",
        "        p = p.view(-1, 32 * 8 * 8)\n",
        "        p = self.policy_fc(p)\n",
        "        policy_out = F.softmax(p, dim=1)\n",
        "\n",
        "        # Value: Tanh [-1, 1]\n",
        "        v = F.relu(self.value_bn(self.value_conv(x)))\n",
        "        v = v.view(-1, 3 * 8 * 8)\n",
        "        v = F.relu(self.value_fc1(v))\n",
        "        v = torch.tanh(self.value_fc2(v))\n",
        "\n",
        "        return policy_out, v"
      ],
      "metadata": {
        "id": "a-KP0l739n1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [CELL 4] Logic Core: ChessConverter\n",
        "class ChessConverter:\n",
        "    def __init__(self):\n",
        "        # 12 channels for pieces (6 types * 2 colors)\n",
        "        self.piece_map = {\n",
        "            'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
        "            'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
        "        }\n",
        "        self.move_to_idx = {}\n",
        "        self.idx_to_move = {}\n",
        "        self.next_idx = 0\n",
        "\n",
        "    # Load/Save Map ƒë·ªÉ ƒë·∫£m b·∫£o nh·∫•t qu√°n khi train nhi·ªÅu l·∫ßn\n",
        "    def load_moves_map(self, path):\n",
        "        if os.path.exists(path):\n",
        "            with open(path, 'rb') as f:\n",
        "                d = pickle.load(f)\n",
        "                self.move_to_idx = d['move_to_idx']\n",
        "                self.idx_to_move = d['idx_to_move']\n",
        "                self.next_idx = len(self.move_to_idx)\n",
        "            print(f\"üìñ Loaded Move Map: {self.next_idx} moves.\")\n",
        "\n",
        "    def save_moves_map(self, path):\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump({'move_to_idx': self.move_to_idx, 'idx_to_move': self.idx_to_move}, f)\n",
        "\n",
        "    def encode_move(self, move_uci):\n",
        "        # T·ª± ƒë·ªông g√°n index cho n∆∞·ªõc ƒëi m·ªõi\n",
        "        if move_uci not in self.move_to_idx:\n",
        "            if self.next_idx >= 4672: return None # Gi·ªõi h·∫°n output\n",
        "            self.move_to_idx[move_uci] = self.next_idx\n",
        "            self.idx_to_move[self.next_idx] = move_uci\n",
        "            self.next_idx += 1\n",
        "        return self.move_to_idx[move_uci]\n",
        "\n",
        "    def board_to_tensor(self, board, prev_board=None):\n",
        "        # Tri·ªÉn khai Tensor 32x8x8 theo t√†i li·ªáu [cite: 30-38]\n",
        "        tensor = np.zeros((32, 8, 8), dtype=np.float32)\n",
        "\n",
        "        # Channel 0-11: Qu√¢n hi·ªán t·∫°i\n",
        "        for sq, pc in board.piece_map().items():\n",
        "            tensor[self.piece_map[pc.symbol()]][chess.square_rank(sq)][chess.square_file(sq)] = 1\n",
        "\n",
        "        # Channel 12-23: Qu√¢n qu√° kh·ª© (History T-1)\n",
        "        if prev_board:\n",
        "            for sq, pc in prev_board.piece_map().items():\n",
        "                tensor[self.piece_map[pc.symbol()]+12][chess.square_rank(sq)][chess.square_file(sq)] = 1\n",
        "\n",
        "        # Channel 24-31: Ph·ª• tr·ª£ (Turn, Castling, En-passant, Repetition)\n",
        "        if board.turn == chess.WHITE: tensor[24,:,:] = 1\n",
        "        if board.has_kingside_castling_rights(chess.WHITE): tensor[25,:,:] = 1\n",
        "        if board.has_queenside_castling_rights(chess.WHITE): tensor[26,:,:] = 1\n",
        "        if board.has_kingside_castling_rights(chess.BLACK): tensor[27,:,:] = 1\n",
        "        if board.has_queenside_castling_rights(chess.BLACK): tensor[28,:,:] = 1\n",
        "        if board.ep_square:\n",
        "            tensor[29][chess.square_rank(board.ep_square)][chess.square_file(board.ep_square)] = 1\n",
        "        if board.is_repetition(1): tensor[30,:,:] = 1\n",
        "        if board.is_repetition(2): tensor[31,:,:] = 1\n",
        "\n",
        "        return tensor"
      ],
      "metadata": {
        "id": "LpJmZsCg9qfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [CELL 5] Data Processing Pipeline\n",
        "def process_data_pipeline(max_games=5000):\n",
        "    #RAW_DIR = os.path.join(DATA_PATH, 'raw_pgn')\n",
        "    OUTPUT_FILE = os.path.join(DATA_PATH, 'processed/combined_data_2000.npz')\n",
        "    MAP_FILE = os.path.join(MODEL_PATH, 'move_map.pkl')\n",
        "\n",
        "    # 1. Setup Converter\n",
        "    converter = ChessConverter()\n",
        "    converter.load_moves_map(MAP_FILE) # Load c≈© n·∫øu c√≥\n",
        "\n",
        "    states, policies, values = [], [], []\n",
        "    pgn_files = [f for f in os.listdir(DATA_PATH) if f.endswith('.pgn')]\n",
        "\n",
        "    if not pgn_files:\n",
        "        print(\"‚ùå Kh√¥ng t√¨m th·∫•y file .pgn n√†o trong folder data/raw_pgn!\")\n",
        "        print(\"üëâ H√£y upload file PGN l√™n Drive tr∆∞·ªõc.\")\n",
        "        return\n",
        "\n",
        "    print(f\"üöÄ Found {len(pgn_files)} files. Processing max {max_games} games...\")\n",
        "\n",
        "    total_games = 0\n",
        "    for pgn_file in pgn_files:\n",
        "        path = os.path.join(DATA_PATH, pgn_file)\n",
        "        pgn = open(path)\n",
        "\n",
        "        while total_games < max_games:\n",
        "            try:\n",
        "                game = chess.pgn.read_game(pgn)\n",
        "            except: break\n",
        "            if game is None: break\n",
        "\n",
        "            # Ch·ªâ l·∫•y v√°n c√≥ k·∫øt qu·∫£ r√µ r√†ng\n",
        "            res = game.headers.get(\"Result\", \"*\")\n",
        "            if res not in [\"1-0\", \"0-1\", \"1/2-1/2\"]: continue\n",
        "            val = 1.0 if res == \"1-0\" else (-1.0 if res == \"0-1\" else 0.0)\n",
        "\n",
        "            board = game.board()\n",
        "            prev_board = None\n",
        "\n",
        "            for move in game.mainline_moves():\n",
        "                s = converter.board_to_tensor(board, prev_board)\n",
        "                m = converter.encode_move(move.uci()) # Serialize move\n",
        "\n",
        "                if m is not None:\n",
        "                    states.append(s)\n",
        "                    policies.append(m)\n",
        "                    values.append(val)\n",
        "\n",
        "                prev_board = board.copy()\n",
        "                board.push(move)\n",
        "\n",
        "            total_games += 1\n",
        "            if total_games % 100 == 0: print(f\"Processing... {total_games} games done.\")\n",
        "\n",
        "    # Save Data\n",
        "    print(\"üì¶ Saving dataset...\")\n",
        "    np.savez_compressed(OUTPUT_FILE, states=np.array(states), policy_targets=np.array(policies), value_targets=np.array(values))\n",
        "    converter.save_moves_map(MAP_FILE)\n",
        "    print(f\"‚úÖ DONE! Saved to {OUTPUT_FILE}\")\n",
        "\n",
        "# Ch·∫°y x·ª≠ l√Ω (Ch·ªâ c·∫ßn ch·∫°y 1 l·∫ßn khi c√≥ d·ªØ li·ªáu m·ªõi)\n",
        "process_data_pipeline(max_games=8000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-hwVzZh9vV8",
        "outputId": "994c97c7-0316-4849-d8e4-e64c47317dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìñ Loaded Move Map: 1908 moves.\n",
            "üöÄ Found 24 files. Processing max 8000 games...\n",
            "Processing... 100 games done.\n",
            "Processing... 200 games done.\n",
            "Processing... 300 games done.\n",
            "Processing... 400 games done.\n",
            "Processing... 500 games done.\n",
            "Processing... 600 games done.\n",
            "Processing... 700 games done.\n",
            "Processing... 800 games done.\n",
            "Processing... 900 games done.\n",
            "Processing... 1000 games done.\n",
            "Processing... 1100 games done.\n",
            "Processing... 1200 games done.\n",
            "Processing... 1300 games done.\n",
            "Processing... 1400 games done.\n",
            "Processing... 1500 games done.\n",
            "Processing... 1600 games done.\n",
            "Processing... 1700 games done.\n",
            "Processing... 1800 games done.\n",
            "Processing... 1900 games done.\n",
            "Processing... 2000 games done.\n",
            "Processing... 2100 games done.\n",
            "Processing... 2200 games done.\n",
            "Processing... 2300 games done.\n",
            "Processing... 2400 games done.\n",
            "Processing... 2500 games done.\n",
            "Processing... 2600 games done.\n",
            "Processing... 2700 games done.\n",
            "Processing... 2800 games done.\n",
            "Processing... 2900 games done.\n",
            "Processing... 3000 games done.\n",
            "Processing... 3100 games done.\n",
            "Processing... 3200 games done.\n",
            "Processing... 3300 games done.\n",
            "Processing... 3400 games done.\n",
            "Processing... 3500 games done.\n",
            "Processing... 3600 games done.\n",
            "Processing... 3700 games done.\n",
            "Processing... 3800 games done.\n",
            "Processing... 3900 games done.\n",
            "Processing... 4000 games done.\n",
            "Processing... 4100 games done.\n",
            "Processing... 4200 games done.\n",
            "Processing... 4300 games done.\n",
            "Processing... 4400 games done.\n",
            "Processing... 4500 games done.\n",
            "Processing... 4600 games done.\n",
            "Processing... 4700 games done.\n",
            "Processing... 4800 games done.\n",
            "Processing... 4900 games done.\n",
            "Processing... 5000 games done.\n",
            "Processing... 5100 games done.\n",
            "Processing... 5200 games done.\n",
            "Processing... 5300 games done.\n",
            "Processing... 5400 games done.\n",
            "Processing... 5500 games done.\n",
            "Processing... 5600 games done.\n",
            "Processing... 5700 games done.\n",
            "Processing... 5800 games done.\n",
            "Processing... 5900 games done.\n",
            "Processing... 6000 games done.\n",
            "Processing... 6100 games done.\n",
            "Processing... 6200 games done.\n",
            "Processing... 6300 games done.\n",
            "Processing... 6400 games done.\n",
            "Processing... 6500 games done.\n",
            "Processing... 6600 games done.\n",
            "Processing... 6700 games done.\n",
            "Processing... 6800 games done.\n",
            "Processing... 6900 games done.\n",
            "Processing... 7000 games done.\n",
            "Processing... 7100 games done.\n",
            "Processing... 7200 games done.\n",
            "Processing... 7300 games done.\n",
            "Processing... 7400 games done.\n",
            "Processing... 7500 games done.\n",
            "Processing... 7600 games done.\n",
            "Processing... 7700 games done.\n",
            "Processing... 7800 games done.\n",
            "Processing... 7900 games done.\n",
            "Processing... 8000 games done.\n",
            "üì¶ Saving dataset...\n",
            "‚úÖ DONE! Saved to /content/drive/MyDrive/TriÃÅ tueÃ£ÃÇ nhaÃÇn taÃ£o/BTL_2/data_chess/data_2000/processed/combined_data_2000.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [CELL 6] High-Speed Dataset (RAM & Local SSD)\n",
        "class InMemoryDataset(Dataset):\n",
        "    def __init__(self, drive_path):\n",
        "        # 1. Copy t·ª´ Drive -> Local (/content) ƒë·ªÉ ƒë·ªçc si√™u nhanh\n",
        "        local_path = '/content/temp_data.npz'\n",
        "        if os.path.exists(drive_path):\n",
        "            print(f\"‚è≥ Copying data from Drive to Local Disk... (Speed Boost)\")\n",
        "            shutil.copy(drive_path, local_path)\n",
        "        else:\n",
        "            print(f\"‚ùå File not found: {drive_path}\")\n",
        "            # T·∫°o data gi·∫£ ƒë·ªÉ test n·∫øu kh√¥ng c√≥ file th·∫≠t\n",
        "            self.generate_dummy()\n",
        "            return\n",
        "\n",
        "        # 2. Load to√†n b·ªô v√†o RAM (Kh·∫Øc ph·ª•c l·ªói zlib v√† ch·∫≠m)\n",
        "        print(\"‚è≥ Loading into RAM...\")\n",
        "        data = np.load(local_path)\n",
        "        self.states = torch.from_numpy(data['states'])\n",
        "        self.p_targets = torch.from_numpy(data['policy_targets']).long()\n",
        "        self.v_targets = torch.from_numpy(data['value_targets']).float()\n",
        "        print(f\"‚úÖ Loaded {len(self.states)} samples ready for training.\")\n",
        "\n",
        "    def generate_dummy(self):\n",
        "        print(\"‚ö†Ô∏è Generating DUMMY data for testing.\")\n",
        "        self.states = torch.randn(1000, 32, 8, 8)\n",
        "        self.p_targets = torch.randint(0, 4672, (1000,)).long()\n",
        "        self.v_targets = torch.randint(-1, 2, (1000,)).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.states)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'state': self.states[idx],\n",
        "            'p_target': self.p_targets[idx],\n",
        "            'v_target': self.v_targets[idx]\n",
        "        }"
      ],
      "metadata": {
        "id": "yxThPC2S9xC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [CELL 7] Training Loop\n",
        "class AlphaZeroLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.nll = nn.NLLLoss() # CrossEntropy cho Policy\n",
        "\n",
        "    def forward(self, p_pred, v_pred, p_target, v_target):\n",
        "        # Loss = (z-v)^2 - pi^T*log(p) [cite: 16]\n",
        "        v_loss = self.mse(v_pred.squeeze(), v_target)\n",
        "        p_loss = self.nll(torch.log(p_pred + 1e-8), p_target)\n",
        "        return v_loss + p_loss, v_loss, p_loss\n",
        "\n",
        "def train(epochs=20, batch_size=256):\n",
        "    DATA_FILE = os.path.join(DATA_PATH, 'processed/combined_data_2000.npz')\n",
        "    MAP_FILE = os.path.join(MODEL_PATH, 'move_map.pkl')\n",
        "\n",
        "    # Load Map ƒë·ªÉ bi·∫øt action_size\n",
        "    converter = ChessConverter()\n",
        "    converter.load_moves_map(MAP_FILE)\n",
        "    action_size = max(converter.next_idx, 4672)\n",
        "\n",
        "    # Setup Dataset (Fast Mode)\n",
        "    dataset = InMemoryDataset(DATA_FILE)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0) # num_workers=0 v√¨ data ƒë√£ ·ªü RAM\n",
        "\n",
        "    # Model Setup\n",
        "    model = SmallResNet(action_size=action_size).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    criterion = AlphaZeroLoss()\n",
        "\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    print(\"üöÄ START TRAINING...\")\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        loop = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for batch in loop:\n",
        "            states = batch['state'].to(device)\n",
        "            p_t = batch['p_target'].to(device)\n",
        "            v_t = batch['v_target'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            p_pred, v_pred = model(states)\n",
        "\n",
        "            loss, v_l, p_l = criterion(p_pred, v_pred, p_t, v_t)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        print(f\"Epoch {epoch+1} finished. Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Save Checkpoint\n",
        "        torch.save(model.state_dict(), os.path.join(MODEL_PATH, 'model_latest_2000.pth'))\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            torch.save(model.state_dict(), os.path.join(MODEL_PATH, 'model_best_2000.pth'))\n",
        "            print(\"üåü Saved new BEST model.\")\n",
        "\n",
        "# RUN TRAINING\n",
        "train(epochs=20)"
      ],
      "metadata": {
        "id": "8om2wCZq9y7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [CELL FINE-TUNE 1] Process NEW 8000 Games\n",
        "# ƒê·∫∑t t√™n file ƒë·∫ßu ra kh√°c ƒëi ƒë·ªÉ ph√¢n bi·ªát v·ªõi ƒë·ª£t 1\n",
        "NEW_DATA_FILE = os.path.join(DATA_PATH, 'processed/batch_4_data.npz')\n",
        "\n",
        "def process_new_batch(max_games=8000):\n",
        "    RAW_DIR = os.path.join(DATA_PATH, 'dt')\n",
        "    MAP_FILE = os.path.join(MODEL_PATH, 'move_map.pkl') # B·∫ÆT BU·ªòC D√ôNG MAP C≈®\n",
        "\n",
        "    # 1. Load Converter v·ªõi Map c≈©\n",
        "    converter = ChessConverter()\n",
        "    if os.path.exists(MAP_FILE):\n",
        "        converter.load_moves_map(MAP_FILE)\n",
        "        print(f\"üìñ Loaded existing map with {converter.next_idx} moves. Ready to extend.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è CRITICAL WARNING: Kh√¥ng t√¨m th·∫•y move_map.pkl c≈©! Model s·∫Ω b·ªã l·ªói index.\")\n",
        "        return\n",
        "\n",
        "    states, policies, values = [], [], []\n",
        "    pgn_files = [f for f in os.listdir(RAW_DIR) if f.endswith('.pgn')]\n",
        "\n",
        "    print(f\"üöÄ Processing new batch from: {pgn_files}\")\n",
        "\n",
        "    total_games = 0\n",
        "    for pgn_file in pgn_files:\n",
        "        path = os.path.join(RAW_DIR, pgn_file)\n",
        "        pgn = open(path)\n",
        "\n",
        "        while total_games < max_games:\n",
        "            try:\n",
        "                game = chess.pgn.read_game(pgn)\n",
        "            except: break\n",
        "            if game is None: break\n",
        "\n",
        "            res = game.headers.get(\"Result\", \"*\")\n",
        "            if res not in [\"1-0\", \"0-1\", \"1/2-1/2\"]: continue\n",
        "            val = 1.0 if res == \"1-0\" else (-1.0 if res == \"0-1\" else 0.0)\n",
        "\n",
        "            board = game.board()\n",
        "            prev_board = None\n",
        "\n",
        "            for move in game.mainline_moves():\n",
        "                s = converter.board_to_tensor(board, prev_board)\n",
        "                m = converter.encode_move(move.uci())\n",
        "\n",
        "                if m is not None:\n",
        "                    states.append(s)\n",
        "                    policies.append(m)\n",
        "                    values.append(val)\n",
        "                prev_board = board.copy()\n",
        "                board.push(move)\n",
        "\n",
        "            total_games += 1\n",
        "            if total_games % 500 == 0: print(f\"  -> Processed {total_games} games...\")\n",
        "\n",
        "    # L∆∞u d·ªØ li·ªáu Batch 2\n",
        "    print(f\"üì¶ Saving Batch 2 dataset ({len(states)} samples)...\")\n",
        "    np.savez_compressed(NEW_DATA_FILE, states=np.array(states), policy_targets=np.array(policies), value_targets=np.array(values))\n",
        "\n",
        "    # C·∫≠p nh·∫≠t l·∫°i Map (n·∫øu c√≥ n∆∞·ªõc ƒëi m·ªõi l·∫° xu·∫•t hi·ªán trong 8000 v√°n n√†y)\n",
        "    converter.save_moves_map(MAP_FILE)\n",
        "    print(f\"‚úÖ DONE! Saved to {NEW_DATA_FILE}\")\n",
        "\n",
        "# Ch·∫°y x·ª≠ l√Ω batch m·ªõi\n",
        "process_new_batch(max_games=8000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G6Ftdue90rF",
        "outputId": "f688f018-73c0-4b4e-8db9-7242250cebf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìñ Loaded Move Map: 1905 moves.\n",
            "üìñ Loaded existing map with 1905 moves. Ready to extend.\n",
            "üöÄ Processing new batch from: ['ficsgamesdb_2012_standard_nomovetimes_925737.pgn', 'ficsgamesdb_2011_standard_nomovetimes_925886.pgn']\n",
            "  -> Processed 500 games...\n",
            "  -> Processed 1000 games...\n",
            "  -> Processed 1500 games...\n",
            "  -> Processed 2000 games...\n",
            "  -> Processed 2500 games...\n",
            "  -> Processed 3000 games...\n",
            "  -> Processed 3500 games...\n",
            "  -> Processed 4000 games...\n",
            "  -> Processed 4500 games...\n",
            "  -> Processed 5000 games...\n",
            "  -> Processed 5500 games...\n",
            "  -> Processed 6000 games...\n",
            "  -> Processed 6500 games...\n",
            "  -> Processed 7000 games...\n",
            "  -> Processed 7500 games...\n",
            "  -> Processed 8000 games...\n",
            "üì¶ Saving Batch 2 dataset (502346 samples)...\n",
            "‚úÖ DONE! Saved to /content/drive/MyDrive/TriÃÅ tueÃ£ÃÇ nhaÃÇn taÃ£o/BTL_2/data_chess/processed/batch_4_data.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [CELL FINE-TUNE 2] Load Weights & Train\n",
        "def fine_tune_model(epochs=10, batch_size=256):\n",
        "    # ƒê∆∞·ªùng d·∫´n file Batch 2 m·ªõi t·∫°o\n",
        "    NEW_DATA_FILE = os.path.join(DATA_PATH, 'processed/batch_4_data.npz')\n",
        "    MAP_FILE = os.path.join(MODEL_PATH, 'move_map.pkl')\n",
        "    PREV_MODEL_PATH = os.path.join(MODEL_PATH, 'model_best.pth') # Model ƒë·ª£t 1\n",
        "\n",
        "    # 1. Setup Resources\n",
        "    converter = ChessConverter()\n",
        "    converter.load_moves_map(MAP_FILE)\n",
        "    action_size = max(converter.next_idx, 4672) # ƒê·∫£m b·∫£o size kh·ªõp v·ªõi map ƒë√£ update\n",
        "\n",
        "    # 2. Load New Dataset\n",
        "    dataset = InMemoryDataset(NEW_DATA_FILE) # Class n√†y ƒë√£ ƒë·ªãnh nghƒ©a ·ªü c√°c cell tr∆∞·ªõc\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    # 3. Initialize Model\n",
        "    model = SmallResNet(action_size=action_size).to(device)\n",
        "\n",
        "    # --- PH·∫¶N QUAN TR·ªåNG NH·∫§T: LOAD WEIGHTS ---\n",
        "    if os.path.exists(PREV_MODEL_PATH):\n",
        "        print(f\"üîÑ Loading weights from previous training: {PREV_MODEL_PATH}\")\n",
        "        # load_state_dict: n·∫°p to√†n b·ªô tham s·ªë w, b c≈© v√†o m·∫°ng m·ªõi\n",
        "        # strict=False: cho ph√©p b·ªè qua l·ªói nh·ªè n·∫øu output size b·ªã thay ƒë·ªïi nh·∫π (do th√™m n∆∞·ªõc ƒëi m·ªõi)\n",
        "        try:\n",
        "            model.load_state_dict(torch.load(PREV_MODEL_PATH, map_location=device), strict=False)\n",
        "            print(\"‚úÖ Weights loaded successfully! Fine-tuning started.\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Warning loading weights: {e}\")\n",
        "            print(\"Tip: N·∫øu l·ªói dimension, c√≥ th·ªÉ do move_map b·ªã reset. H√£y ki·ªÉm tra l·∫°i.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y model c≈©. S·∫Ω train t·ª´ ƒë·∫ßu (Scratch).\")\n",
        "\n",
        "    # 4. Optimizer v·ªõi Learning Rate TH·∫§P H∆†N\n",
        "    # Gi·∫£m LR xu·ªëng 1e-4 (so v·ªõi 1e-3 l√∫c ƒë·∫ßu) ƒë·ªÉ tinh ch·ªânh nh·∫π nh√†ng\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "    criterion = AlphaZeroLoss()\n",
        "\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    # 5. Training Loop (Gi·ªëng h·ªát c≈©)\n",
        "    print(\"üöÄ START FINE-TUNING...\")\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        loop = tqdm(loader, desc=f\"Fine-tune Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for batch in loop:\n",
        "            states = batch['state'].to(device)\n",
        "            p_t = batch['p_target'].to(device)\n",
        "            v_t = batch['v_target'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            p_pred, v_pred = model(states)\n",
        "\n",
        "            loss, v_l, p_l = criterion(p_pred, v_pred, p_t, v_t)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        print(f\"Epoch {epoch+1} finished. Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # L∆∞u ƒë√® l√™n model best hi·ªán t·∫°i n·∫øu t·ªët h∆°n\n",
        "        torch.save(model.state_dict(), os.path.join(MODEL_PATH, 'model_latest.pth'))\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            # B·∫°n c√≥ th·ªÉ l∆∞u th√†nh t√™n kh√°c nh∆∞ 'model_finetuned.pth' n·∫øu mu·ªën gi·ªØ file c≈©\n",
        "            torch.save(model.state_dict(), os.path.join(MODEL_PATH, 'model_best.pth'))\n",
        "            print(\"üåü Checkpoint updated.\")\n",
        "\n",
        "# Ch·∫°y Fine-tune\n",
        "fine_tune_model(epochs=10) # 10 Epochs l√† ƒë·ªß cho fine-tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfqF4gCSULZ-",
        "outputId": "83838cbb-207e-4470-d0ca-7138caad63ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìñ Loaded Move Map: 1908 moves.\n",
            "‚è≥ Copying data from Drive to Local Disk... (Speed Boost)\n",
            "‚è≥ Loading into RAM...\n",
            "‚úÖ Loaded 502346 samples ready for training.\n",
            "üîÑ Loading weights from previous training: /content/drive/MyDrive/TriÃÅ tueÃ£ÃÇ nhaÃÇn taÃ£o/BTL_2/weights/model_best.pth\n",
            "‚úÖ Weights loaded successfully! Fine-tuning started.\n",
            "üöÄ START FINE-TUNING...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tune Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1963/1963 [00:53<00:00, 36.72it/s, loss=3.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished. Avg Loss: 3.8943\n",
            "üåü Checkpoint updated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tune Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1963/1963 [00:52<00:00, 37.39it/s, loss=2.86]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished. Avg Loss: 3.1142\n",
            "üåü Checkpoint updated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tune Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1963/1963 [00:52<00:00, 37.34it/s, loss=2.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished. Avg Loss: 2.8376\n",
            "üåü Checkpoint updated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tune Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1963/1963 [00:52<00:00, 37.69it/s, loss=2.73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished. Avg Loss: 2.5981\n",
            "üåü Checkpoint updated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tune Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1963/1963 [00:52<00:00, 37.71it/s, loss=2.48]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished. Avg Loss: 2.3905\n",
            "üåü Checkpoint updated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tune Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1963/1963 [00:51<00:00, 37.90it/s, loss=1.88]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished. Avg Loss: 2.2074\n",
            "üåü Checkpoint updated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tune Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1963/1963 [00:51<00:00, 37.92it/s, loss=1.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished. Avg Loss: 2.0475\n",
            "üåü Checkpoint updated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tune Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1963/1963 [00:51<00:00, 37.86it/s, loss=1.85]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished. Avg Loss: 1.9058\n",
            "üåü Checkpoint updated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tune Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1963/1963 [00:52<00:00, 37.74it/s, loss=1.77]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished. Avg Loss: 1.7794\n",
            "üåü Checkpoint updated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fine-tune Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1963/1963 [00:52<00:00, 37.66it/s, loss=1.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished. Avg Loss: 1.6660\n",
            "üåü Checkpoint updated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "import chess.svg\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- 1. ƒê·ªäNH NGHƒ®A AGENT ---\n",
        "\n",
        "class RandomAgent:\n",
        "    def select_move(self, board):\n",
        "        # Ch·ªçn ng·∫´u nhi√™n 1 n∆∞·ªõc trong c√°c n∆∞·ªõc h·ª£p l·ªá\n",
        "        moves = list(board.legal_moves)\n",
        "        return random.choice(moves) if moves else None\n",
        "\n",
        "class NeuralAgent:\n",
        "    def __init__(self, model_path, map_path, device):\n",
        "        self.device = device\n",
        "\n",
        "        # Load Converter & Map\n",
        "        self.converter = ChessConverter()\n",
        "        self.converter.load_moves_map(map_path)\n",
        "\n",
        "        # Load Model\n",
        "        action_size = max(self.converter.next_idx, 4672)\n",
        "        self.model = SmallResNet(action_size=action_size).to(device)\n",
        "        # Load weights (ch·∫•p nh·∫≠n strict=False ƒë·ªÉ tr√°nh l·ªói nh·ªè v·ªÅ size)\n",
        "        self.model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
        "        self.model.eval()\n",
        "\n",
        "    def select_move(self, board):\n",
        "        # 1. Chuy·ªÉn ƒë·ªïi b√†n c·ªù sang Tensor\n",
        "        state = self.converter.board_to_tensor(board)\n",
        "        state_t = torch.tensor(state).unsqueeze(0).to(self.device) # [1, 32, 8, 8]\n",
        "\n",
        "        # 2. Predict\n",
        "        with torch.no_grad():\n",
        "            policy, value = self.model(state_t)\n",
        "\n",
        "        # 3. L·ªçc n∆∞·ªõc ƒëi h·ª£p l·ªá (Masking)\n",
        "        legal_moves = list(board.legal_moves)\n",
        "        best_move = None\n",
        "        best_prob = -1.0\n",
        "\n",
        "        # Duy·ªát qua c√°c n∆∞·ªõc h·ª£p l·ªá ƒë·ªÉ t√¨m n∆∞·ªõc c√≥ x√°c su·∫•t cao nh·∫•t theo Neural Net\n",
        "        policy_np = policy.cpu().numpy()[0] # Vector x√°c su·∫•t\n",
        "\n",
        "        for move in legal_moves:\n",
        "            move_uci = move.uci()\n",
        "            # L·∫•y index c·ªßa n∆∞·ªõc ƒëi t·ª´ map\n",
        "            idx = self.converter.move_to_idx.get(move_uci, None)\n",
        "\n",
        "            if idx is not None and idx < len(policy_np):\n",
        "                prob = policy_np[idx]\n",
        "                if prob > best_prob:\n",
        "                    best_prob = prob\n",
        "                    best_move = move\n",
        "\n",
        "        # Fallback: N·∫øu kh√¥ng t√¨m th·∫•y n∆∞·ªõc n√†o trong map (hi·∫øm), ch·ªçn random\n",
        "        if best_move is None and legal_moves:\n",
        "            print(\"‚ö†Ô∏è Model confused (Move not in map). Random pick.\")\n",
        "            return random.choice(legal_moves)\n",
        "\n",
        "        return best_move\n",
        "\n",
        "# --- 2. H√ÄM CH·∫†Y ƒê·∫§U (ARENA) ---\n",
        "\n",
        "def play_match(model_path, map_path, num_games=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"üèüÔ∏è Starting Arena on {device}...\")\n",
        "\n",
        "    # Kh·ªüi t·∫°o ƒë·∫•u th·ªß\n",
        "    neural_player = NeuralAgent(model_path, map_path, device)\n",
        "    random_player = RandomAgent()\n",
        "\n",
        "    results = {\"Neural_Win\": 0, \"Random_Win\": 0, \"Draw\": 0}\n",
        "\n",
        "    for i in range(num_games):\n",
        "        board = chess.Board()\n",
        "\n",
        "        # ƒê·ªïi m√†u qu√¢n sau m·ªói v√°n ƒë·ªÉ c√¥ng b·∫±ng\n",
        "        # V√°n ch·∫µn: Neural c·∫ßm Tr·∫Øng (White)\n",
        "        # V√°n l·∫ª: Neural c·∫ßm ƒêen (Black)\n",
        "        neural_is_white = (i % 2 == 0)\n",
        "\n",
        "        print(f\"\\n--- Game {i+1}/{num_games} ---\")\n",
        "        print(f\"Neural plays {'White' if neural_is_white else 'Black'}\")\n",
        "\n",
        "        move_count = 0\n",
        "        while not board.is_game_over(claim_draw=True):\n",
        "            # X√°c ƒë·ªãnh l∆∞·ª£t ƒëi\n",
        "            if board.turn == chess.WHITE:\n",
        "                current_player = neural_player if neural_is_white else random_player\n",
        "            else:\n",
        "                current_player = random_player if neural_is_white else neural_player\n",
        "\n",
        "            # Agent ch·ªçn n∆∞·ªõc ƒëi\n",
        "            move = current_player.select_move(board)\n",
        "            board.push(move)\n",
        "            move_count += 1\n",
        "\n",
        "            # (T√πy ch·ªçn) In b√†n c·ªù m·ªói 10 n∆∞·ªõc ƒë·ªÉ ƒë·ª° lag log\n",
        "            # if move_count % 10 == 0: print(\".\", end=\"\")\n",
        "\n",
        "        # K·∫øt th√∫c v√°n\n",
        "        res = board.result()\n",
        "        print(f\"\\nGame Over: {res} (Moves: {move_count})\")\n",
        "\n",
        "        # Ph√¢n ƒë·ªãnh th·∫Øng thua\n",
        "        if res == \"1-0\":\n",
        "            winner = \"Neural\" if neural_is_white else \"Random\"\n",
        "        elif res == \"0-1\":\n",
        "            winner = \"Random\" if neural_is_white else \"Neural\"\n",
        "        else:\n",
        "            winner = \"Draw\"\n",
        "\n",
        "        if winner == \"Neural\": results[\"Neural_Win\"] += 1\n",
        "        elif winner == \"Random\": results[\"Random_Win\"] += 1\n",
        "        else: results[\"Draw\"] += 1\n",
        "\n",
        "        print(f\"Winner: {winner}\")\n",
        "\n",
        "    print(\"\\n================ RESULT ================\")\n",
        "    print(f\"Neural Win: {results['Neural_Win']}\")\n",
        "    print(f\"Random Win: {results['Random_Win']}\")\n",
        "    print(f\"Draw:       {results['Draw']}\")\n",
        "    print(\"========================================\")\n",
        "\n",
        "# --- 3. TH·ª∞C THI ---\n",
        "# ƒê·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n ƒë√∫ng\n",
        "MODEL_FILE = os.path.join(MODEL_PATH, 'model_best_2000.pth')\n",
        "MAP_FILE = os.path.join(MODEL_PATH, 'move_map.pkl')\n",
        "\n",
        "if os.path.exists(MODEL_FILE):\n",
        "    play_match(MODEL_FILE, MAP_FILE, num_games=10)\n",
        "else:\n",
        "    print(\"‚ùå Ch∆∞a c√≥ file model. H√£y train tr∆∞·ªõc!\")"
      ],
      "metadata": {
        "id": "ntLyPm_aYKG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm  # Thanh ti·∫øn tr√¨nh\n",
        "import time\n",
        "\n",
        "# --- C·∫§U H√åNH ---\n",
        "NUM_GAMES = 1000          # S·ªë l∆∞·ª£ng v√°n\n",
        "MAX_MOVES_PER_GAME = 150  # Gi·ªõi h·∫°n n∆∞·ªõc ƒëi ƒë·ªÉ tr√°nh treo m√°y (X·ª≠ h√≤a n·∫øu v∆∞·ª£t qu√°)\n",
        "MODEL_FILE = os.path.join(MODEL_PATH, 'model_best_2000.pth')\n",
        "MAP_FILE = os.path.join(MODEL_PATH, 'move_map.pkl')\n",
        "\n",
        "# --- ƒê·ªäNH NGHƒ®A L·∫†I AGENT (ƒê·ªÉ ƒë·∫£m b·∫£o t√≠nh nh·∫•t qu√°n) ---\n",
        "class RandomAgent:\n",
        "    def select_move(self, board):\n",
        "        moves = list(board.legal_moves)\n",
        "        return random.choice(moves) if moves else None\n",
        "\n",
        "class NeuralAgent:\n",
        "    def __init__(self, model_path, map_path, device):\n",
        "        self.device = device\n",
        "        self.converter = ChessConverter()\n",
        "        self.converter.load_moves_map(map_path)\n",
        "\n",
        "        # Load Model\n",
        "        action_size = max(self.converter.next_idx, 4672)\n",
        "        self.model = SmallResNet(action_size=action_size).to(device)\n",
        "\n",
        "        if os.path.exists(model_path):\n",
        "            self.model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
        "            self.model.eval()\n",
        "        else:\n",
        "            raise FileNotFoundError(\"‚ùå Kh√¥ng t√¨m th·∫•y file model!\")\n",
        "\n",
        "    def select_move(self, board):\n",
        "        # Bi·∫øn ƒë·ªïi b√†n c·ªù\n",
        "        state = self.converter.board_to_tensor(board)\n",
        "        state_t = torch.tensor(state).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            policy, _ = self.model(state_t)\n",
        "\n",
        "        legal_moves = list(board.legal_moves)\n",
        "        policy_np = policy.cpu().numpy()[0]\n",
        "\n",
        "        best_move = None\n",
        "        best_prob = -1.0\n",
        "\n",
        "        # L·∫•y n∆∞·ªõc ƒëi t·ªët nh·∫•t trong c√°c n∆∞·ªõc h·ª£p l·ªá\n",
        "        for move in legal_moves:\n",
        "            idx = self.converter.move_to_idx.get(move.uci(), None)\n",
        "            if idx is not None and idx < len(policy_np):\n",
        "                if policy_np[idx] > best_prob:\n",
        "                    best_prob = policy_np[idx]\n",
        "                    best_move = move\n",
        "\n",
        "        # Fallback random n·∫øu g·∫∑p l·ªói l·∫°\n",
        "        return best_move if best_move else random.choice(legal_moves)\n",
        "\n",
        "# --- H√ÄM CH·∫†Y BENCHMARK ---\n",
        "def run_benchmark():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"üöÄ Starting Benchmark: {NUM_GAMES} games on {device}...\")\n",
        "\n",
        "    try:\n",
        "        neural_bot = NeuralAgent(MODEL_FILE, MAP_FILE, device)\n",
        "        random_bot = RandomAgent()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading agent: {e}\")\n",
        "        return\n",
        "\n",
        "    stats = {\"Win\": 0, \"Loss\": 0, \"Draw\": 0}\n",
        "    start_time = time.time()\n",
        "\n",
        "    # D√πng tqdm ƒë·ªÉ hi·ªán thanh loading\n",
        "    for i in tqdm(range(NUM_GAMES), desc=\"Simulating\"):\n",
        "        board = chess.Board()\n",
        "\n",
        "        # Ch·∫µn: Neural c·∫ßm Tr·∫Øng | L·∫ª: Neural c·∫ßm ƒêen\n",
        "        neural_is_white = (i % 2 == 0)\n",
        "\n",
        "        white_player = neural_bot if neural_is_white else random_bot\n",
        "        black_player = random_bot if neural_is_white else neural_bot\n",
        "\n",
        "        move_count = 0\n",
        "        game_result = None # None: ch∆∞a xong\n",
        "\n",
        "        # V√≤ng l·∫∑p v√°n ƒë·∫•u\n",
        "        while not board.is_game_over():\n",
        "            if move_count >= MAX_MOVES_PER_GAME:\n",
        "                game_result = \"Draw (Timeout)\" # X·ª≠ h√≤a n·∫øu ƒë√°nh qu√° l√¢u\n",
        "                break\n",
        "\n",
        "            if board.turn == chess.WHITE:\n",
        "                move = white_player.select_move(board)\n",
        "            else:\n",
        "                move = black_player.select_move(board)\n",
        "\n",
        "            board.push(move)\n",
        "            move_count += 1\n",
        "\n",
        "        # X√°c ƒë·ªãnh k·∫øt qu·∫£\n",
        "        if game_result is None:\n",
        "            res = board.result() # \"1-0\", \"0-1\", \"1/2-1/2\"\n",
        "        else:\n",
        "            res = \"1/2-1/2\" # Timeout coi nh∆∞ h√≤a\n",
        "\n",
        "        # T√≠nh ƒëi·ªÉm cho Neural Network\n",
        "        if res == \"1-0\":\n",
        "            if neural_is_white: stats[\"Win\"] += 1\n",
        "            else: stats[\"Loss\"] += 1\n",
        "        elif res == \"0-1\":\n",
        "            if neural_is_white: stats[\"Loss\"] += 1\n",
        "            else: stats[\"Win\"] += 1\n",
        "        else:\n",
        "            stats[\"Draw\"] += 1\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    # --- HI·ªÇN TH·ªä B√ÅO C√ÅO ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"üìä BENCHMARK REPORT ({NUM_GAMES} Games)\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"üèÜ WINS:   {stats['Win']} ({stats['Win']/NUM_GAMES*100:.2f}%)\")\n",
        "    print(f\"‚ùå LOSSES: {stats['Loss']} ({stats['Loss']/NUM_GAMES*100:.2f}%)\")\n",
        "    print(f\"ü§ù DRAWS:  {stats['Draw']} ({stats['Draw']/NUM_GAMES*100:.2f}%)\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"‚è±Ô∏è Total Time: {total_time:.1f}s\")\n",
        "    print(f\"‚ö° Speed: {NUM_GAMES/total_time:.2f} games/sec\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "# Ch·∫°y lu√¥n\n",
        "run_benchmark()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8HlsRWmXVZb",
        "outputId": "d362c267-cfdb-4101-f468-45e77dfee709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting Benchmark: 1000 games on cuda...\n",
            "üìñ Loaded Move Map: 1914 moves.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Simulating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:40<00:00,  9.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "üìä BENCHMARK REPORT (1000 Games)\n",
            "========================================\n",
            "üèÜ WINS:   576 (57.60%)\n",
            "‚ùå LOSSES: 1 (0.10%)\n",
            "ü§ù DRAWS:  423 (42.30%)\n",
            "----------------------------------------\n",
            "‚è±Ô∏è Total Time: 100.8s\n",
            "‚ö° Speed: 9.92 games/sec\n",
            "========================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}